# Exploratory Data Analysis (EDA) for Customer Churn Propensity Model
## Dataset Description
These are the descriptions of the dimensions from the dataframe that was shared on Kaggle:
- <b>CustomerID</b>: Unique customer ID
- <b>Churn</b>: Churn Flag
- <b>Tenure</b>: Tenure of customer in organization
- <b>PreferredLoginDevice</b>: Preferred login device of customer
- <b>CityTier</b>: City tier
- <b>WarehouseToHome</b>: Distance in between warehouse to home of customer
- <b>PreferredPaymentMode</b>: Preferred payment method of customer
- <b>Gender</b>: Gender of customer
- <b>HourSpendOnApp</b>: Number of hours spend on mobile application or website
- <b>NumberOfDeviceRegistered</b>: Total number of deceives is registered on particular customer
- <b>PreferedOrderCat</b>: Preferred order category of customer in last month
- <b>SatisfactionScore</b>: Satisfactory score of customer on service
- <b>MaritalStatus</b>: Marital status of customer
- <b>NumberOfAddress</b>: Total number of added added on particular customer
- <b>Complain</b>: Any complaint has been raised in last month
- <b>OrderAmountHikeFromlastYear</b>: Percentage increases in order from last year
- <b>CouponUsed</b>: Total number of coupon has been used in last month
- <b>OrderCount</b>: Total number of orders has been places in last month
- <b>DaySinceLastOrder</b>: Day Since last order by customer
- <b>CashbackAmount</b>: Average cashback in last month

## Statistical observations
- Despite this data containing customer ID numbers, cardinality is not present. It appears that the interactions generated by each customer may be aggregated into 1 row per ID but could represent multiple transactions with the company. I'm not sure if this is the case as the description doesn't seem to contain much detail over how this data was generated. But, I'm going to make the assumption that this is the case, and in saying that, I would say that this is likely to harm the predictive accuracy of the upcoming model. In saying that, my research may prove me wrong!
- If we ignore the `CustomerID` column, more than half of the dimensions (10 out of 19) in the dataset are Categorical/Ordinal in nature, with the majority of them containing non-binary (but multiple) categories.
- Given that this dataset has a strong emphasis on categorical dimensions, I thought it best to employ Phi K ($φ_K$) correlation to assess any strong correlations that may exist between categorical and ordinal variables. This would serve as a heads up for any statistical red flags that could potentially harm the predictive accuracy of the upcoming model. Before going into that, some notes on $φ_K$ correlation:
    - As stipulated by the <a href='https://arxiv.org/pdf/1811.11440'>research paper</a> $φ_K$ is an extension of the traditional Phi coefficient. The extension of this measure of correlation was designed for Machine Learning applications. Since ML/AI applications tend to deal in large and complex datasets, the 'K' aspect was designed to help understand complex high correlations between multiple categorical/ordinal variables. In so doing, help identify risky features during EDA/Feature Selection to avoid multicollinearity, amongst other gremlins that might creep into an ML/AI model.
    - The <a href='https://phik.readthedocs.io/en/latest/'>Python implementation</a> of the aforementioned research paper does allow us to run a more detailed analysis that goes beyond the `y-data profiling` report. Whilst, y-data profiling claims a Phi K implementation, a closer examination of this revealed that it actually only runs a traditional <a href='https://en.wikipedia.org/wiki/Phi_coefficient'>Phi Correlation test (or the Matthews Correlation Coefficient)</a>. This only allows for the calculation of binary (categorical) categoricals but not ordinal or interval variables. The closer examination was conducted by way of attempting to cast the `SatisfactionScore` as an ordinal variable in the `df_schema` (since it's a Satisfaction Score, I would regard that as a ranked categorical variable), but y-data profiling wouldn't accept it!
    - 